{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "1agGD7uP493Q"
   },
   "outputs": [],
   "source": [
    "#https://medium.com/@kenneth.ca95/a-guide-to-transfer-learning-with-keras-using-resnet50-a81a4a28084b\n",
    "# Running the version as 1.x is optional, without that first line it will run the last version of tensorflow for Colab.\n",
    "\n",
    "#import keras\n",
    "import tensorflow as tf \n",
    "from tensorflow import keras\n",
    "import tensorflow.keras as K\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Flatten, Activation\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "\n",
    "import pandas as pd\n",
    "#from keras.utils import plot_model\n",
    "from keras.utils.vis_utils import plot_model\n",
    "#from keras.utils import np_utils\n",
    "from keras import utils as np_utils\n",
    "#from keras.utils import to_categorical\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "pd.set_option('display.max_columns',None)#displaying long list of columns\n",
    "pd.set_option('display.max_rows', None)#displaying long list of rows\n",
    "pd.set_option('display.width', 1000)#width of window\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "MUEuZsobBTUF"
   },
   "outputs": [],
   "source": [
    "# Load data\n",
    "# CIFAR-10 is a dataset with 60000 32x32 colour images grouped in 10 classes, that means 6000 images per class. \n",
    "# This is a dataset of 50,000 32x32 color training images and 10,000 test images, labeled over 10 categories.\n",
    "# The categories are airplane, automobile, beer, cat, deer, dog, frog, horse, ship, truck. \n",
    "# We can take advantage of the fact that these categories and a lot more are into the Imagenet collection.\n",
    "# Loading the CIFAR-10 datasets\n",
    "from keras.datasets import cifar10\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "29Bq-NQmCDgS"
   },
   "outputs": [],
   "source": [
    "# Preprocess data function\n",
    "# Now that the data is loaded, we are going to build a preprocess function for the data. \n",
    "# We have X as a numpy array of shape (m, 32, 32, 1) where m is the number of images, \n",
    "# 28 and 28 the dimensions, and 1 is because we use grayscale images. \n",
    "# We have a set of X for training and a set of X for validation. \n",
    "# Y is a numpy array of shape (m, ) that we want to be our labels. \n",
    "# Since we work with 10 different categories, we make use of one-hot encoding with a \n",
    "# function of Keras that makes our Y into a shape of (m, 10). That also applies for the validation.\n",
    "\n",
    "def preprocess_data(X,Y):\n",
    "  X_p = K.applications.xception.preprocess_input(X)\n",
    "  Y_p = K.utils.to_categorical(Y,10)\n",
    "  return X_p, Y_p\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Q4qZ9aHTEQUp",
    "outputId": "ffe37f98-fecb-46ae-a035-ddb6445be0ae"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz\n",
      "170498071/170498071 [==============================] - 13s 0us/step\n",
      "x_train shape: (50000, 32, 32, 3)\n",
      "y_train shape: (50000, 1)\n",
      "x_test shape: (10000, 32, 32, 3)\n",
      "y_test shape: (10000, 1)\n"
     ]
    }
   ],
   "source": [
    "# load and split data\n",
    "# The data, split between train and test sets:\n",
    "# (x_train, y_train), (x_test, y_test) = K.datasets.cifar100.load_data()\n",
    "(x_train, y_train), (x_test, y_test) = cifar10.load_data()\n",
    "img_rows, img_cols = 32, 32\n",
    "print('x_train shape:', x_train.shape)\n",
    "print('y_train shape:', y_train.shape)\n",
    "print('x_test shape:', x_test.shape)\n",
    "print('y_test shape:', y_test.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "aAs88uCaFMc3",
    "outputId": "89e2eea3-30b1-4162-fd61-deee4b59f10f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train shape: (50000, 32, 32, 3)\n",
      "y_train shape: (50000, 10)\n",
      "x_test shape: (10000, 32, 32, 3)\n",
      "y_test shape: (10000, 10)\n"
     ]
    }
   ],
   "source": [
    "# Preprocess data\n",
    "# Next, we are going to call our function with the parameters loaded from the Fashion Mnist database.\n",
    "\n",
    "x_train, y_train = preprocess_data(x_train, y_train)\n",
    "x_test, y_test = preprocess_data(x_test, y_test)\n",
    "print('x_train shape:', x_train.shape)\n",
    "print('y_train shape:', y_train.shape)\n",
    "print('x_test shape:', x_test.shape)\n",
    "print('y_test shape:', y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "vDEpJYeWGK46",
    "outputId": "cd796c35-975c-4832-915a-2c139da64d48"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/resnet/resnet50_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
      "94765736/94765736 [==============================] - 5s 0us/step\n"
     ]
    }
   ],
   "source": [
    "# Using weights of a trained neural network\n",
    "# A pretrained model from the Keras Applications has the advantage of allow you to use weights that\n",
    "# are already calibrated to make predictions. In this case, we use the weights from Imagenet \n",
    "# and the network is a ResNet50. The option include_top=False allows feature extraction by removing \n",
    "# the last dense layers. This let us control the output and input of the model.\n",
    "\n",
    "input_t = keras.Input(shape=(32,32,3))\n",
    "res_model = keras.applications.ResNet50(include_top=False,\n",
    "                                    weights=\"imagenet\",\n",
    "                                    input_tensor=input_t)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "hlyKjCtPH3m3"
   },
   "outputs": [],
   "source": [
    "# In this case, we ‘freeze’ all layers except for the last block of the ResNet50.\n",
    "\n",
    "for layer in res_model.layers[:120]:\n",
    "  layer.trainable=False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "JdixTKJ7I10V",
    "outputId": "a7179264-587c-4d1f-d280-94f52c77b343"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 input_1 - False\n",
      "1 conv1_pad - False\n",
      "2 conv1_conv - False\n",
      "3 conv1_bn - False\n",
      "4 conv1_relu - False\n",
      "5 pool1_pad - False\n",
      "6 pool1_pool - False\n",
      "7 conv2_block1_1_conv - False\n",
      "8 conv2_block1_1_bn - False\n",
      "9 conv2_block1_1_relu - False\n",
      "10 conv2_block1_2_conv - False\n",
      "11 conv2_block1_2_bn - False\n",
      "12 conv2_block1_2_relu - False\n",
      "13 conv2_block1_0_conv - False\n",
      "14 conv2_block1_3_conv - False\n",
      "15 conv2_block1_0_bn - False\n",
      "16 conv2_block1_3_bn - False\n",
      "17 conv2_block1_add - False\n",
      "18 conv2_block1_out - False\n",
      "19 conv2_block2_1_conv - False\n",
      "20 conv2_block2_1_bn - False\n",
      "21 conv2_block2_1_relu - False\n",
      "22 conv2_block2_2_conv - False\n",
      "23 conv2_block2_2_bn - False\n",
      "24 conv2_block2_2_relu - False\n",
      "25 conv2_block2_3_conv - False\n",
      "26 conv2_block2_3_bn - False\n",
      "27 conv2_block2_add - False\n",
      "28 conv2_block2_out - False\n",
      "29 conv2_block3_1_conv - False\n",
      "30 conv2_block3_1_bn - False\n",
      "31 conv2_block3_1_relu - False\n",
      "32 conv2_block3_2_conv - False\n",
      "33 conv2_block3_2_bn - False\n",
      "34 conv2_block3_2_relu - False\n",
      "35 conv2_block3_3_conv - False\n",
      "36 conv2_block3_3_bn - False\n",
      "37 conv2_block3_add - False\n",
      "38 conv2_block3_out - False\n",
      "39 conv3_block1_1_conv - False\n",
      "40 conv3_block1_1_bn - False\n",
      "41 conv3_block1_1_relu - False\n",
      "42 conv3_block1_2_conv - False\n",
      "43 conv3_block1_2_bn - False\n",
      "44 conv3_block1_2_relu - False\n",
      "45 conv3_block1_0_conv - False\n",
      "46 conv3_block1_3_conv - False\n",
      "47 conv3_block1_0_bn - False\n",
      "48 conv3_block1_3_bn - False\n",
      "49 conv3_block1_add - False\n",
      "50 conv3_block1_out - False\n",
      "51 conv3_block2_1_conv - False\n",
      "52 conv3_block2_1_bn - False\n",
      "53 conv3_block2_1_relu - False\n",
      "54 conv3_block2_2_conv - False\n",
      "55 conv3_block2_2_bn - False\n",
      "56 conv3_block2_2_relu - False\n",
      "57 conv3_block2_3_conv - False\n",
      "58 conv3_block2_3_bn - False\n",
      "59 conv3_block2_add - False\n",
      "60 conv3_block2_out - False\n",
      "61 conv3_block3_1_conv - False\n",
      "62 conv3_block3_1_bn - False\n",
      "63 conv3_block3_1_relu - False\n",
      "64 conv3_block3_2_conv - False\n",
      "65 conv3_block3_2_bn - False\n",
      "66 conv3_block3_2_relu - False\n",
      "67 conv3_block3_3_conv - False\n",
      "68 conv3_block3_3_bn - False\n",
      "69 conv3_block3_add - False\n",
      "70 conv3_block3_out - False\n",
      "71 conv3_block4_1_conv - False\n",
      "72 conv3_block4_1_bn - False\n",
      "73 conv3_block4_1_relu - False\n",
      "74 conv3_block4_2_conv - False\n",
      "75 conv3_block4_2_bn - False\n",
      "76 conv3_block4_2_relu - False\n",
      "77 conv3_block4_3_conv - False\n",
      "78 conv3_block4_3_bn - False\n",
      "79 conv3_block4_add - False\n",
      "80 conv3_block4_out - False\n",
      "81 conv4_block1_1_conv - False\n",
      "82 conv4_block1_1_bn - False\n",
      "83 conv4_block1_1_relu - False\n",
      "84 conv4_block1_2_conv - False\n",
      "85 conv4_block1_2_bn - False\n",
      "86 conv4_block1_2_relu - False\n",
      "87 conv4_block1_0_conv - False\n",
      "88 conv4_block1_3_conv - False\n",
      "89 conv4_block1_0_bn - False\n",
      "90 conv4_block1_3_bn - False\n",
      "91 conv4_block1_add - False\n",
      "92 conv4_block1_out - False\n",
      "93 conv4_block2_1_conv - False\n",
      "94 conv4_block2_1_bn - False\n",
      "95 conv4_block2_1_relu - False\n",
      "96 conv4_block2_2_conv - False\n",
      "97 conv4_block2_2_bn - False\n",
      "98 conv4_block2_2_relu - False\n",
      "99 conv4_block2_3_conv - False\n",
      "100 conv4_block2_3_bn - False\n",
      "101 conv4_block2_add - False\n",
      "102 conv4_block2_out - False\n",
      "103 conv4_block3_1_conv - False\n",
      "104 conv4_block3_1_bn - False\n",
      "105 conv4_block3_1_relu - False\n",
      "106 conv4_block3_2_conv - False\n",
      "107 conv4_block3_2_bn - False\n",
      "108 conv4_block3_2_relu - False\n",
      "109 conv4_block3_3_conv - False\n",
      "110 conv4_block3_3_bn - False\n",
      "111 conv4_block3_add - False\n",
      "112 conv4_block3_out - False\n",
      "113 conv4_block4_1_conv - False\n",
      "114 conv4_block4_1_bn - False\n",
      "115 conv4_block4_1_relu - False\n",
      "116 conv4_block4_2_conv - False\n",
      "117 conv4_block4_2_bn - False\n",
      "118 conv4_block4_2_relu - False\n",
      "119 conv4_block4_3_conv - False\n",
      "120 conv4_block4_3_bn - True\n",
      "121 conv4_block4_add - True\n",
      "122 conv4_block4_out - True\n",
      "123 conv4_block5_1_conv - True\n",
      "124 conv4_block5_1_bn - True\n",
      "125 conv4_block5_1_relu - True\n",
      "126 conv4_block5_2_conv - True\n",
      "127 conv4_block5_2_bn - True\n",
      "128 conv4_block5_2_relu - True\n",
      "129 conv4_block5_3_conv - True\n",
      "130 conv4_block5_3_bn - True\n",
      "131 conv4_block5_add - True\n",
      "132 conv4_block5_out - True\n",
      "133 conv4_block6_1_conv - True\n",
      "134 conv4_block6_1_bn - True\n",
      "135 conv4_block6_1_relu - True\n",
      "136 conv4_block6_2_conv - True\n",
      "137 conv4_block6_2_bn - True\n",
      "138 conv4_block6_2_relu - True\n",
      "139 conv4_block6_3_conv - True\n",
      "140 conv4_block6_3_bn - True\n",
      "141 conv4_block6_add - True\n",
      "142 conv4_block6_out - True\n",
      "143 conv5_block1_1_conv - True\n",
      "144 conv5_block1_1_bn - True\n",
      "145 conv5_block1_1_relu - True\n",
      "146 conv5_block1_2_conv - True\n",
      "147 conv5_block1_2_bn - True\n",
      "148 conv5_block1_2_relu - True\n",
      "149 conv5_block1_0_conv - True\n",
      "150 conv5_block1_3_conv - True\n",
      "151 conv5_block1_0_bn - True\n",
      "152 conv5_block1_3_bn - True\n",
      "153 conv5_block1_add - True\n",
      "154 conv5_block1_out - True\n",
      "155 conv5_block2_1_conv - True\n",
      "156 conv5_block2_1_bn - True\n",
      "157 conv5_block2_1_relu - True\n",
      "158 conv5_block2_2_conv - True\n",
      "159 conv5_block2_2_bn - True\n",
      "160 conv5_block2_2_relu - True\n",
      "161 conv5_block2_3_conv - True\n",
      "162 conv5_block2_3_bn - True\n",
      "163 conv5_block2_add - True\n",
      "164 conv5_block2_out - True\n",
      "165 conv5_block3_1_conv - True\n",
      "166 conv5_block3_1_bn - True\n",
      "167 conv5_block3_1_relu - True\n",
      "168 conv5_block3_2_conv - True\n",
      "169 conv5_block3_2_bn - True\n",
      "170 conv5_block3_2_relu - True\n",
      "171 conv5_block3_3_conv - True\n",
      "172 conv5_block3_3_bn - True\n",
      "173 conv5_block3_add - True\n",
      "174 conv5_block3_out - True\n"
     ]
    }
   ],
   "source": [
    "# We can check that we did it correctly with:\n",
    "# False means that the layer is ‘freezed’ or is not trainable and \n",
    "# True that when we run our model, the weights are going to be adjusted.\n",
    "\n",
    "for i, layer in enumerate(res_model.layers):\n",
    "  print(i,layer.name,\"-\",layer.trainable)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "3PHC3U6xJceX"
   },
   "outputs": [],
   "source": [
    "    # Add Flatten and Dense layers on top of Resnet\n",
    "    # Now, we need to connect our pretrained model with the new layers \n",
    "    # of our model. We can use global pooling or a flatten layer to connect \n",
    "    # the dimensions of the previous layers with the new layers. \n",
    "    \n",
    "    # to_res = (224, 224)\n",
    "    to_res = (32, 32)\n",
    "    model = K.models.Sequential()\n",
    "    model.add(K.layers.Lambda(lambda image: tf.image.resize(image, to_res))) \n",
    "    model.add(res_model)\n",
    "    model.add(K.layers.Flatten())\n",
    "    model.add(K.layers.BatchNormalization())\n",
    "    model.add(K.layers.Dense(256, activation='relu'))\n",
    "    model.add(K.layers.Dropout(0.5))\n",
    "    model.add(K.layers.BatchNormalization())\n",
    "    model.add(K.layers.Dense(128, activation='relu'))\n",
    "    model.add(K.layers.Dropout(0.5))\n",
    "    model.add(K.layers.BatchNormalization())\n",
    "   # model.add(K.layers.Dense(64, activation='relu'))\n",
    "   # model.add(K.layers.Dropout(0.5))\n",
    "   # model.add(K.layers.BatchNormalization())\n",
    "    model.add(K.layers.Dense(10, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "NClKTTPoJwjA",
    "outputId": "8f8129f8-1107-4393-8857-a1fd07d0ab75"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "1563/1563 [==============================] - 67s 39ms/step - loss: 2.0505 - accuracy: 0.2980 - val_loss: 1.7742 - val_accuracy: 0.3608\n",
      "Epoch 2/20\n",
      "1563/1563 [==============================] - 60s 39ms/step - loss: 1.9655 - accuracy: 0.3300 - val_loss: 1.7988 - val_accuracy: 0.3861\n",
      "Epoch 3/20\n",
      "1563/1563 [==============================] - 61s 39ms/step - loss: 1.8885 - accuracy: 0.3546 - val_loss: 1.7056 - val_accuracy: 0.3982\n",
      "Epoch 4/20\n",
      "1563/1563 [==============================] - 61s 39ms/step - loss: 1.8183 - accuracy: 0.3785 - val_loss: 1.6993 - val_accuracy: 0.4216\n",
      "Epoch 5/20\n",
      "1563/1563 [==============================] - 60s 38ms/step - loss: 1.7592 - accuracy: 0.4021 - val_loss: 1.5552 - val_accuracy: 0.4650\n",
      "Epoch 6/20\n",
      "1563/1563 [==============================] - 59s 38ms/step - loss: 1.7146 - accuracy: 0.4156 - val_loss: 1.5928 - val_accuracy: 0.4607\n",
      "Epoch 7/20\n",
      "1563/1563 [==============================] - 60s 38ms/step - loss: 1.6703 - accuracy: 0.4315 - val_loss: 1.5516 - val_accuracy: 0.4625\n",
      "Epoch 8/20\n",
      "1563/1563 [==============================] - 60s 38ms/step - loss: 1.6258 - accuracy: 0.4427 - val_loss: 1.5381 - val_accuracy: 0.4671\n",
      "Epoch 9/20\n",
      "1563/1563 [==============================] - 60s 38ms/step - loss: 1.5827 - accuracy: 0.4613 - val_loss: 1.4698 - val_accuracy: 0.4906\n",
      "Epoch 10/20\n",
      "1563/1563 [==============================] - 59s 38ms/step - loss: 1.5560 - accuracy: 0.4700 - val_loss: 1.5022 - val_accuracy: 0.4871\n",
      "Epoch 11/20\n",
      "1563/1563 [==============================] - 60s 38ms/step - loss: 1.5223 - accuracy: 0.4822 - val_loss: 1.4296 - val_accuracy: 0.5085\n",
      "Epoch 12/20\n",
      "1563/1563 [==============================] - 60s 38ms/step - loss: 1.4932 - accuracy: 0.4926 - val_loss: 1.4414 - val_accuracy: 0.5129\n",
      "Epoch 13/20\n",
      "1563/1563 [==============================] - 60s 38ms/step - loss: 1.4665 - accuracy: 0.5043 - val_loss: 1.5558 - val_accuracy: 0.4685\n",
      "Epoch 14/20\n",
      "1563/1563 [==============================] - 61s 39ms/step - loss: 1.4345 - accuracy: 0.5149 - val_loss: 1.9817 - val_accuracy: 0.4330\n",
      "Epoch 15/20\n",
      "1563/1563 [==============================] - 60s 38ms/step - loss: 1.4031 - accuracy: 0.5259 - val_loss: 1.4159 - val_accuracy: 0.5153\n",
      "Epoch 16/20\n",
      "1563/1563 [==============================] - 60s 38ms/step - loss: 1.3805 - accuracy: 0.5329 - val_loss: 1.6527 - val_accuracy: 0.4724\n",
      "Epoch 17/20\n",
      "1563/1563 [==============================] - 60s 38ms/step - loss: 1.3567 - accuracy: 0.5434 - val_loss: 2.0635 - val_accuracy: 0.3735\n",
      "Epoch 18/20\n",
      "1563/1563 [==============================] - 60s 38ms/step - loss: 1.3367 - accuracy: 0.5516 - val_loss: 1.9931 - val_accuracy: 0.4111\n",
      "Epoch 19/20\n",
      "1563/1563 [==============================] - 60s 38ms/step - loss: 1.3076 - accuracy: 0.5616 - val_loss: 1.3826 - val_accuracy: 0.5353\n",
      "Epoch 20/20\n",
      "1563/1563 [==============================] - 61s 39ms/step - loss: 1.2837 - accuracy: 0.5702 - val_loss: 1.5068 - val_accuracy: 0.4833\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " lambda (Lambda)             (None, 32, 32, 3)         0         \n",
      "                                                                 \n",
      " resnet50 (Functional)       (None, 1, 1, 2048)        23587712  \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 2048)              0         \n",
      "                                                                 \n",
      " batch_normalization (BatchN  (None, 2048)             8192      \n",
      " ormalization)                                                   \n",
      "                                                                 \n",
      " dense (Dense)               (None, 256)               524544    \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 256)               0         \n",
      "                                                                 \n",
      " batch_normalization_1 (Batc  (None, 256)              1024      \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 128)               32896     \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 128)               0         \n",
      "                                                                 \n",
      " batch_normalization_2 (Batc  (None, 128)              512       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 10)                1290      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 24,156,170\n",
      "Trainable params: 17,779,082\n",
      "Non-trainable params: 6,377,088\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Compile model and train\n",
    "# Results\n",
    "# We obtained an accuracy of 94% on training set and 90% on validation with 10 epochs.\n",
    "# In the 8th epoch, the values are very similar and it is interesting to note that \n",
    "# in the first validation accuracy is higher than training. \n",
    "# This is because of dropout use, which in Keras, it has a different behavior \n",
    "# for training and testing. In testing time, all the features are ready and \n",
    "# the dropout is turned off, resulting in a better accuracy. \n",
    "# This readjust on the last epochs since the model continues changing on the training.\n",
    "\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "                  optimizer=K.optimizers.RMSprop(lr=2e-5),\n",
    "                  metrics=['accuracy'])\n",
    "history = model.fit(x_train, y_train, batch_size=32, epochs=20, verbose=1,\n",
    "                        validation_data=(x_test, y_test)\n",
    "                       )\n",
    "model.summary()\n"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
